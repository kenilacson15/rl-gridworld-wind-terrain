# ğŸŒªï¸ GridWorld with Wind and Stochastic Terrain

A custom 2D reinforcement learning environment for exploring core RL concepts such as value iteration, policy learning, and stochastic transitions. This project simulates dynamic terrains and wind zones to create a challenging, educational environment for RL experimentation.

---

## ğŸ“Œ Project Goal

Build an original, beginner-friendly RL environment to help solidify foundational concepts:

- Markov Decision Processes (MDPs)
- Value and Policy Iteration
- Transition Probability Modeling
- Exploration vs. Exploitation

---

## âœ¨ Features

- âœ… **Grid-based environment**: Agent navigation in a customizable grid
- ğŸŒ¬ï¸ **Wind zones**: Affect agent movement direction
- ğŸ§Š **Terrain types**: Ice (slippery), swamp (slow/sticky), and more
- ğŸ² **Stochastic & deterministic dynamics**: Realistic RL challenges
- ğŸ“Š **Classical planning algorithms**: Value iteration, policy iteration

---

## ğŸš€ Quick Start

1. **Clone the repository:**
   ```powershell
   git clone <repo-url>
   cd rl-gridworld-wind-terrain
   ```
2. **Install dependencies:**
   ```powershell
   pip install -r requirements.txt
   ```
3. **Run a sample experiment:**
   ```powershell
   python src/main.py
   ```

---

## ğŸ“ Project Structure

```bash
gridworld-rl/
â”‚
â”œâ”€â”€ src/                # Environment logic, agent models
â”‚   â”œâ”€â”€ envs/           # Environment classes
â”‚   â”œâ”€â”€ agents/         # Agent implementations
â”‚   â”œâ”€â”€ utils/          # Utility functions
â”‚   â””â”€â”€ main.py         # Entry point
â”‚
â”œâ”€â”€ notebooks/          # Experimentation & visualization
â”œâ”€â”€ data/               # Raw and processed data
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ models/             # Saved models and logs
â”‚   â”œâ”€â”€ trained/
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ reports/            # Generated analysis and reports
â”œâ”€â”€ tests/              # Unit and integration tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ Getting Started

- Check out the `notebooks/` folder for interactive demos.
- Modify `src/envs/` to create custom environments.
- Use `src/agents/` to implement new RL agents.

---

## ğŸ¤ Contributing

Contributions are welcome! Please open issues or submit pull requests for new features, bug fixes, or improvements.

---

## ğŸ“„ License

[MIT License](LICENSE)
